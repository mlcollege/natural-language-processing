{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec in Gensim\n",
    "\n",
    "Implement a simple word2vec estimator using [Gensim](https://radimrehurek.com/gensim/). Use the small Wikipedia corpus from '../data/corpora/enlang1.txt'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-02-01 15:56:46,386 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2018-02-01 15:56:46,389 : INFO : collecting all words and their counts\n",
      "2018-02-01 15:56:46,390 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-02-01 15:56:47,257 : INFO : collected 175177 word types from a corpus of 4873383 raw words and 5000 sentences\n",
      "2018-02-01 15:56:47,258 : INFO : Loading a fresh vocabulary\n",
      "2018-02-01 15:56:47,601 : INFO : min_count=3 retains 62837 unique words (35% of original 175177, drops 112340)\n",
      "2018-02-01 15:56:47,602 : INFO : min_count=3 leaves 4736664 word corpus (97% of original 4873383, drops 136719)\n",
      "2018-02-01 15:56:47,770 : INFO : deleting the raw counts dictionary of 175177 items\n",
      "2018-02-01 15:56:47,780 : INFO : sample=0.001 downsamples 26 most-common words\n",
      "2018-02-01 15:56:47,782 : INFO : downsampling leaves estimated 3788259 word corpus (80.0% of prior 4736664)\n",
      "2018-02-01 15:56:47,783 : INFO : estimated required memory for 62837 words and 50 dimensions: 56553300 bytes\n",
      "2018-02-01 15:56:48,008 : INFO : resetting layer weights\n",
      "2018-02-01 15:56:48,496 : INFO : training model with 3 workers on 62837 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-02-01 15:56:49,499 : INFO : PROGRESS: at 6.13% examples, 1205335 words/s, in_qsize 5, out_qsize 0\n",
      "2018-02-01 15:56:50,500 : INFO : PROGRESS: at 12.74% examples, 1241897 words/s, in_qsize 5, out_qsize 0\n",
      "2018-02-01 15:56:51,510 : INFO : PROGRESS: at 19.88% examples, 1248331 words/s, in_qsize 5, out_qsize 0\n",
      "2018-02-01 15:56:52,518 : INFO : PROGRESS: at 26.43% examples, 1251291 words/s, in_qsize 6, out_qsize 0\n",
      "2018-02-01 15:56:53,523 : INFO : PROGRESS: at 33.04% examples, 1255968 words/s, in_qsize 6, out_qsize 0\n",
      "2018-02-01 15:56:54,525 : INFO : PROGRESS: at 40.14% examples, 1257622 words/s, in_qsize 5, out_qsize 0\n",
      "2018-02-01 15:56:55,529 : INFO : PROGRESS: at 46.78% examples, 1262323 words/s, in_qsize 5, out_qsize 0\n",
      "2018-02-01 15:56:56,533 : INFO : PROGRESS: at 53.57% examples, 1267962 words/s, in_qsize 5, out_qsize 0\n",
      "2018-02-01 15:56:57,541 : INFO : PROGRESS: at 60.71% examples, 1269113 words/s, in_qsize 6, out_qsize 0\n",
      "2018-02-01 15:56:58,543 : INFO : PROGRESS: at 67.36% examples, 1269056 words/s, in_qsize 6, out_qsize 0\n",
      "2018-02-01 15:56:59,546 : INFO : PROGRESS: at 73.87% examples, 1269256 words/s, in_qsize 5, out_qsize 0\n",
      "2018-02-01 15:57:00,547 : INFO : PROGRESS: at 80.91% examples, 1269946 words/s, in_qsize 5, out_qsize 0\n",
      "2018-02-01 15:57:01,548 : INFO : PROGRESS: at 87.79% examples, 1271782 words/s, in_qsize 5, out_qsize 0\n",
      "2018-02-01 15:57:02,554 : INFO : PROGRESS: at 94.38% examples, 1271813 words/s, in_qsize 5, out_qsize 0\n",
      "2018-02-01 15:57:03,466 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-02-01 15:57:03,477 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-02-01 15:57:03,487 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-02-01 15:57:03,488 : INFO : training on 24366915 raw words (18892496 effective words) took 15.0s, 1260413 effective words/s\n"
     ]
    }
   ],
   "source": [
    "import gensim, logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "sentences = []\n",
    "with open('../data/corpora/enlang1.txt') as f:\n",
    "    for line in f.readlines():\n",
    "        sentences.append(line.strip().split())\n",
    "\n",
    "model = gensim.models.Word2Vec(sentences, size = 50, min_count=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.20474598  1.451848   -1.0239041   0.42626384  2.9364133   2.5634243\n",
      "  0.94328135 -0.11614431 -1.1550511   0.6351805  -0.27550706 -0.91280895\n",
      "  0.8834353   0.16459714 -2.0092673   0.6252315  -0.6797438  -1.5800899\n",
      "  0.44569865  1.788979   -0.23695281  1.0348423  -0.5377606   1.8198183\n",
      " -1.0216933  -0.23971567  1.2494572   0.33862925  1.5519047   1.6086415\n",
      " -1.559984    0.8733524   0.20594183 -3.7557235  -2.2541203   0.0679892\n",
      "  0.5491095   1.5905684  -0.5127586   2.8371532  -2.9389822  -0.01068709\n",
      "  0.25589764 -1.4922242   0.85257924  2.8131728  -0.21944268  3.9228218\n",
      " -0.4912506  -2.195461  ]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv['car'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-02-01 15:57:03,542 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('buses', 0.8922812938690186),\n",
       " ('routes', 0.8808276057243347),\n",
       " ('bts', 0.8472105264663696),\n",
       " ('platforms', 0.8464639186859131),\n",
       " ('roads', 0.8395819664001465),\n",
       " ('trains', 0.8203502893447876),\n",
       " ('rail', 0.8144564628601074),\n",
       " ('freight', 0.8041046261787415),\n",
       " ('retail', 0.8016695976257324),\n",
       " ('suburban', 0.799876868724823)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['cars', 'bus'], negative=['car'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import better models\n",
    "\n",
    "Import word vectors trained on [Common Crawl](https://fasttext.cc/docs/en/english-vectors.html) corpus (600 B tokens) and play with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-02-01 15:57:03,653 : INFO : loading projection weights from ../data/crawl-300.vec\n",
      "2018-02-01 15:58:34,941 : INFO : loaded (500000, 300) matrix from ../data/crawl-300.vec\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "word_vectors = KeyedVectors.load_word2vec_format('../data/crawl-300.vec', binary=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-02-01 15:58:34,947 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('queens', 0.838758111000061),\n",
       " ('queen.', 0.6004167795181274),\n",
       " ('monarchs', 0.5899762511253357),\n",
       " ('Queen', 0.5859925150871277),\n",
       " ('empresses', 0.5775150656700134),\n",
       " ('princes', 0.5499585866928101),\n",
       " ('QUEEN', 0.5448766350746155),\n",
       " ('royals', 0.5442696213722229),\n",
       " ('princesses', 0.5383291840553284),\n",
       " ('royal', 0.5232111215591431)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar(positive=['kings', 'queen'], negative=['king'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wife', 0.7529045343399048),\n",
       " ('daughter', 0.6500850915908813),\n",
       " ('mother-in-law', 0.6470040678977966),\n",
       " ('spouse', 0.6457177996635437),\n",
       " ('husbands', 0.633111298084259),\n",
       " ('mother', 0.6005339622497559),\n",
       " ('ex-husband', 0.5952433347702026),\n",
       " ('daughter-in-law', 0.5948172807693481),\n",
       " ('ex-wife', 0.5728636384010315),\n",
       " ('daughters', 0.5600826144218445)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar(positive=['woman', 'husband'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Madrid', 0.8625081181526184),\n",
       " ('Barcelona', 0.7637038826942444),\n",
       " ('Sevilla', 0.6874054670333862),\n",
       " ('Seville', 0.6747833490371704),\n",
       " ('Malaga', 0.6494930386543274),\n",
       " ('Zaragoza', 0.645937442779541),\n",
       " ('Valencia', 0.6383104920387268),\n",
       " ('Alicante', 0.6115807890892029),\n",
       " ('Salamanca', 0.6041631102561951),\n",
       " ('Murcia', 0.6019024848937988)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar(positive=['Paris', 'Spain'], negative=['France'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Vladimir', 0.644631028175354),\n",
       " ('Medvedev', 0.6112760901451111),\n",
       " ('Sergei', 0.5950400233268738),\n",
       " ('Dmitry', 0.5793238878250122),\n",
       " ('Oleg', 0.5696351528167725),\n",
       " ('Denis', 0.5639139413833618),\n",
       " ('Mikhail', 0.5574285387992859),\n",
       " ('Anatoly', 0.5540498495101929),\n",
       " ('Igor', 0.5533066987991333),\n",
       " ('Ivan', 0.5529454350471497)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar(positive=['Donald', 'Putin'], negative=['Trump'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
