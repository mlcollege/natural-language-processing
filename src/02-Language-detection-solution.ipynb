{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "02-Language-detection-solution.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKKsn2epPUPY",
        "colab_type": "text"
      },
      "source": [
        "# Language detection using language models\n",
        "\n",
        "The goal of this task is to implement a detector of the English language using language models. You will compute the perplexity of an investigated text given the English language model and decide whether the text is written in English based on a perplexity threshold."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpQQ_ksPPUPi",
        "colab_type": "text"
      },
      "source": [
        "## Create an English language model\n",
        "\n",
        "Load English Wikipedia texts from ‘enlang1.txt’ and create an English bigram model – ie. Compute unigram histograms, bigram histograms and the size of vocabulary (number of unique characters).\n",
        "\n",
        "Experiment with different language models, e.g. a trigram model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvA3LAbeTwLa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://raw.githubusercontent.com/mlcollege/natural-language-processing/master/data/corpora/cslang.txt\n",
        "!wget https://raw.githubusercontent.com/mlcollege/natural-language-processing/master/data/corpora/enlang1.txt\n",
        "!wget https://raw.githubusercontent.com/mlcollege/natural-language-processing/master/data/corpora/enlang2.txt\n",
        "!wget https://raw.githubusercontent.com/mlcollege/natural-language-processing/master/data/corpora/eslang.txt\n",
        "!wget https://raw.githubusercontent.com/mlcollege/natural-language-processing/master/data/corpora/frlang.txt\n",
        "!wget https://raw.githubusercontent.com/mlcollege/natural-language-processing/master/data/corpora/itlang.txt\n",
        "!wget https://raw.githubusercontent.com/mlcollege/natural-language-processing/master/data/corpora/rulang.txt\n",
        "!wget https://raw.githubusercontent.com/mlcollege/natural-language-processing/master/data/corpora/mixedlang.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvcdkxaJPUPj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('enlang1.txt') as fin:\n",
        "    print(fin.readlines()[0][:200])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_JaUsnlPUPq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "V = 0 #size of vocabulary\n",
        "histogram = {} #unigram and bigram frequencies\n",
        "\n",
        "with open('enlang1.txt') as fin:\n",
        "    for doc in fin.readlines():\n",
        "        for i in range(len(doc)-2):\n",
        "            bigram = doc[i:i+2]\n",
        "            unigram = doc[i]\n",
        "            histogram[bigram] = histogram.get(bigram, 0) + 1\n",
        "            histogram[unigram] = histogram.get(unigram, 0) + 1\n",
        "    V = len([unigram for unigram in histogram.keys() if len(unigram) == 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pqFT35-PUPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(V)\n",
        "print(histogram['en'])\n",
        "print(histogram['e'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DTlY__KPUPz",
        "colab_type": "text"
      },
      "source": [
        "## Define the function for computing perplexity. \n",
        "\n",
        "The function should take a string as a parameter and return its perplexity based on the language model from above. Use the Laplace smoothing for probability estimation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvKP7BQBPUP0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "#Compute the probability of a bigram using the Laplace smoothing\n",
        "def getProbability(bigram):\n",
        "    return 1.0*(histogram.get(bigram, 0) + 1) / \\\n",
        "                (histogram.get(bigram[0], 0) + V)\n",
        "\n",
        "# Get the perplexity of text.\n",
        "def getPerplexity(text):\n",
        "    bigrams = [text[i:i+2] for i in range(len(text) - 1)]\n",
        "    h = -sum(map(lambda x: np.log2(getProbability(x)), bigrams))\n",
        "    return np.power(2, h/len(bigrams))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mvt2WCNtPUP2",
        "colab_type": "text"
      },
      "source": [
        "## Compute perplexities\n",
        "\n",
        "Compute perplexities of various text corpora from Wikipedia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnQAFzi6PUP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = './'\n",
        "\n",
        "languages = {'en': {'file': 'enlang2.txt'},\n",
        "             #'cs': {'file': 'cslang.txt'},\n",
        "             #'es': {'file': 'eslang.txt'},\n",
        "             #'fr': {'file': 'frlang.txt'},\n",
        "             #'it': {'file': 'itlang.txt'},\n",
        "             #'ru': {'file': 'rulang.txt'},\n",
        "             'mixed': {'file': 'mixedlang.txt'}\n",
        "            }\n",
        "\n",
        "for lang, v in languages.items():\n",
        "    with open(PATH + v['file']) as fin:\n",
        "        perplexities = []\n",
        "        for doc in fin.readlines():\n",
        "            doc = doc.strip()\n",
        "            perplexities.append(getPerplexity(doc))\n",
        "        languages[lang]['perplexities'] = perplexities"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bWi65BhPUP5",
        "colab_type": "text"
      },
      "source": [
        "## Plot histograms\n",
        "\n",
        "Plot perplexity histograms of the English and mixed corpora. Decide what the best threshold for detecting the English language is. Visualize perplexities of the other corpora. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNkWt9CTPUP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x1 = languages['en']['perplexities']\n",
        "x2 = languages['mixed']['perplexities']\n",
        "\n",
        "mu1 = np.mean(x1)\n",
        "sigma1 = np.std(x1)\n",
        "print(\"Mean and standard deviation of the first dataset: mean={}, std={}.\".format(mu1, sigma1))\n",
        "\n",
        "mu2 = np.mean(x2)\n",
        "sigma2 = np.std(x2)\n",
        "print(\"Mean and standard deviation of the second dataset: mean={}, std={}.\".format(mu2, sigma2))\n",
        "\n",
        "# histograms of perplexities\n",
        "plt.hist(x1, bins='auto', density=1, facecolor='blue', alpha=0.8)\n",
        "plt.hist(x2, bins=1000, density=1, facecolor='red', alpha=0.8)\n",
        "\n",
        "plt.xlabel('Perplexity')\n",
        "plt.ylabel('Density')\n",
        "plt.axis([8, 20, 0, 0.55])\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzSgDPSuPUQD",
        "colab_type": "text"
      },
      "source": [
        "## Language detector\n",
        "\n",
        "Implement and test the ‘detectLang’ function, which takes a string as the input and returns true if the string is written in English. It returns False otherwise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNX6OeVqPUQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def detectLang(text, threshold=14):\n",
        "    text = text.lower() #The training corpus was also in the lowercase form.\n",
        "    if len(text) <= 1:\n",
        "        return False\n",
        "    else:\n",
        "        return True if getPerplexity(text) <= threshold else False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLRSuRzdPUQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(detectLang('this is an example of the english language'))\n",
        "print(detectLang('another text written in the target language which should pass'))\n",
        "print(detectLang('toto je ukázkový český text'))\n",
        "print(detectLang('následuje alternativní posloupnost znaků'))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}