{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Travel agency's review generator\n",
    "\n",
    "Implement a text generator, which imitates reviewers of a travel agency using the LSTM language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A voucher to nowhere #skypickerfail 2400 out of pocket due to skypicker delays in their booking office', 'I booked with Kiwi for the first time, just a short flight from GÃ¶teborg to London. I had forgotten my middle name in the fill-out section and was quite worried I had to pay for another ticket. Dominika and Nikola resolved the situation in good time with no extra cost. Thank you very much, will be booking again!']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "reviews = pd.read_csv('../data/en_reviews.csv', sep='\\t', header=None, names =['rating', 'text'])\n",
    "reviews = reviews['text'].tolist()\n",
    "print(reviews[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training data\n",
    "\n",
    "Create one long string of all reviews separated by the new line symbol. First, we need to replace all new lines from the source data with spaces. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = '\\n'.join(map(lambda x: x.replace('\\n', ' '), reviews))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of all characters and their integer representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(data)))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "print(len(chars))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create character sequences of MAXLEN length and a list that stores the characters occuring right after the sequence in the training data. The next sequence starts STEP characters after the beginning of the previous sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXLEN = 40\n",
    "STEP = 20\n",
    "\n",
    "sequences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(data) - MAXLEN, STEP):\n",
    "    sequences.append(data[i: i + MAXLEN])\n",
    "    next_chars.append(data[i + MAXLEN])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = np.zeros((len(sequences), MAXLEN, len(chars)), dtype=np.bool)\n",
    "y_train = np.zeros((len(sequences), len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, sequences in enumerate(sequences):\n",
    "    for t, char in enumerate(sequences):\n",
    "        X_train[i, t, char_indices[char]] = 1\n",
    "        y_train[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build an LSTM language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(MAXLEN, len(chars)), dropout=0.5))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a helper function for sampling characters from a probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the function which generates reviews using an LSTM language model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(seed, temperature=1.0):\n",
    "    sentence = MAXLEN * '\\n' + seed\n",
    "    sentence = sentence[-MAXLEN:]\n",
    "    generated = seed\n",
    "\n",
    "    next_char = None\n",
    "    while next_char != '\\n':\n",
    "        X_pred = np.zeros((1, MAXLEN, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            X_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "        y_pred = model.predict(X_pred, verbose=0)[0]\n",
    "        next_index = sample(y_pred, temperature)\n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "    return generated[0:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model and print a sample after every iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Epoch 1/1\n",
      " 49152/116306 [===========>..................] - ETA: 1:39 - loss: 3.1394"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "old_loss = None\n",
    "for iteration in range(1, EPOCHS + 1):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "            \n",
    "    history = model.fit(X_train, y_train, batch_size=128, epochs=1)\n",
    "    loss = history.history['loss'][0]\n",
    "    if old_loss != None and old_loss < loss:\n",
    "        print(\"Loss explosion.\")\n",
    "        break\n",
    "    old_loss = loss\n",
    "    start_index = np.random.randint(0, len(data) - MAXLEN - 1)\n",
    "    sentence = data[start_index: start_index + MAXLEN]\n",
    "    print(generate(sentence))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
