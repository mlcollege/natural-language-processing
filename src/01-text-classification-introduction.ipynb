{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "01-text-classification-introduction.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqBcpU9CPQtT",
        "colab_type": "text"
      },
      "source": [
        "# Introduction to text classification\n",
        "\n",
        "We will illustrate basic text classification approchaches on [\n",
        "SMS Spam Collection](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection) data set. \n",
        "The SMS Spam Collection is a set of SMS tagged messages that have been collected for SMS Spam research. It contains one set of SMS messages in English of 5,574 messages, tagged acording being ham (legitimate) or spam."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQjSt9SXPQtX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f85c935c-71bc-4362-ef5a-0469a4881886"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/mlcollege/natural-language-processing/master/data/spam.csv', sep='\\t')\n",
        "df.head()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Target</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Target                                               Text\n",
              "0    ham  Go until jurong point, crazy.. Available only ...\n",
              "1    ham                      Ok lar... Joking wif u oni...\n",
              "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3    ham  U dun say so early hor... U c already then say...\n",
              "4    ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHj6g3eoPQtb",
        "colab_type": "text"
      },
      "source": [
        "## Preparation of train and test data sets\n",
        "\n",
        "Separate and rename target values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJGOdV9JPQtc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = df['Text']\n",
        "target = df['Target'].replace('ham', 1).replace('spam', 0)\n",
        "names = ['spam', 'ham']\n",
        "print(data[:5])\n",
        "print(target[:5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUQ1YDt0PQte",
        "colab_type": "text"
      },
      "source": [
        "Shuffle the data and split it to train and test parts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijMnO8uSPQtf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2)\n",
        "print('Train size: {}'.format(len(X_train)))\n",
        "print('Test size: {}'.format(len(X_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NcOcGHGPQtj",
        "colab_type": "text"
      },
      "source": [
        "## Data preprocessing\n",
        "\n",
        "Tokenize the texts. Experiment with various tokenizers from the [NLTK](http://www.nltk.org/api/nltk.tokenize.html) library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eafsKD5-PQtj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize.casual import casual_tokenize\n",
        "\n",
        "sms = data[4]\n",
        "print(sms)\n",
        "\n",
        "tokenizer = lambda text: casual_tokenize(text, preserve_case=False)\n",
        "\n",
        "print(tokenizer(sms))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GN-d9JTJPQtn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "print(stopwords.words('english'))\n",
        "stopword_tokenizer = lambda text: [w for w in tokenizer(text) if not w in set(stopwords.words('english'))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWvp0fyVPQtp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stopword_tokenizer(sms)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGsIOJTZPQtr",
        "colab_type": "text"
      },
      "source": [
        "Convert tokens to their stems. Experiment with stemmers and lemmatizers from the [NLTK](http://www.nltk.org/api/nltk.stem.html) library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubwAEAWiPQtr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "stem_tokenizer = lambda text: [stemmer.stem(w) for w in stopword_tokenizer(text)]\n",
        "\n",
        "print (stem_tokenizer(sms))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuDUrMhNPQtt",
        "colab_type": "text"
      },
      "source": [
        "Fit a vectorizer which converts texts to count vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5m8ZQQ-PQtu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer(tokenizer=stem_tokenizer)\n",
        "vectorizer.fit(X_train)\n",
        "print (vectorizer.transform([sms]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ntghj4fwPQtw",
        "colab_type": "text"
      },
      "source": [
        "Convert count vectors to TFIDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3CkbR5YPQtx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "tfidf_transformer.fit(vectorizer.transform(X_train))\n",
        "print(tfidf_transformer.transform(vectorizer.transform([sms])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HyzLGEHPQt0",
        "colab_type": "text"
      },
      "source": [
        "## Classification\n",
        "\n",
        "Train a classifier using the following models:\n",
        "* [Logistic regression](http://scikit-learn.org/0.15/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
        "* [Gradient Boosted Trees](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html) (Experiment with different depths and number of trees)\n",
        "* [Support Vector Machines](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC) (experiment with different kernels)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0vaZGwKPQt1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "clf_pipeline = Pipeline([('vec', vectorizer),\n",
        "                         ('tfidf', tfidf_transformer),\n",
        "                         #('lr', LogisticRegression())\n",
        "                         #('gbc', GradientBoostingClassifier(n_estimators=100, max_depth=4))\n",
        "                         ('svm', svm.SVC(kernel='linear'))\n",
        "                        ])\n",
        "clf_pipeline.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9IiR3XtPQt6",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "Compute common classification metrics and evaluate the models. Decide which model performs best on the given problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JVSENovPQt6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = clf_pipeline.predict(X_test)\n",
        "\n",
        "print (\"Test accuracy: {:.5f}\".format(accuracy_score(y_test, y_pred)))\n",
        "print ()\n",
        "print(metrics.classification_report(y_test, y_pred, digits=4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HO8M7ajxPQt9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KN4RhIPlPQt_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = clf_pipeline.predict(X_train)\n",
        "\n",
        "print (\"Train accuracy: {:.2f}\".format(accuracy_score(y_train, y_pred)))\n",
        "print ()\n",
        "print(metrics.classification_report(y_train, y_pred, digits=4))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
