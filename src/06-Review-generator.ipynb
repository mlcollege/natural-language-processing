{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "06-Review-generator.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OB_iRPOMPYEx",
        "colab_type": "text"
      },
      "source": [
        "# Travel agency's review generator\n",
        "\n",
        "Implement a text generator, which imitates reviewers of a travel agency using the LSTM language model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zP0wZaZRPYE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "reviews = pd.read_csv('https://raw.githubusercontent.com/mlcollege/natural-language-processing/master/data/en_reviews.csv', sep='\\t', header=None, names =['rating', 'text'])\n",
        "reviews = reviews['text'].tolist()\n",
        "print(reviews[:2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lM63eDubPYFD",
        "colab_type": "text"
      },
      "source": [
        "## Prepare training data\n",
        "\n",
        "Create one long string of all reviews separated by the new line symbol. First, we need to replace all new lines from the source data with spaces. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz5vl2q5PYFE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = '\\n'.join(map(lambda x: x.replace('\\n', ' '), reviews))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGYj2eEDPYFV",
        "colab_type": "text"
      },
      "source": [
        "Create a list of all characters and their integer representations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udDOL64xPYFy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chars = sorted(list(set(data)))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "print(len(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcB0dhTKPYF7",
        "colab_type": "text"
      },
      "source": [
        "Create character sequences of MAXLEN length and a list that stores the characters occuring right after the sequence in the training data. The next sequence starts STEP characters after the beginning of the previous sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jU3b5kyPYGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAXLEN = 40\n",
        "STEP = 10\n",
        "\n",
        "sequences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(data) - MAXLEN, STEP):\n",
        "    sequences.append(data[i: i + MAXLEN])\n",
        "    next_chars.append(data[i + MAXLEN])\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iAsELhtPYGg",
        "colab_type": "text"
      },
      "source": [
        "Create the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O6pqEwCPYGh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "X_train = np.zeros((len(sequences), MAXLEN, len(chars)), dtype=np.bool)\n",
        "y_train = np.zeros((len(sequences), len(chars)), dtype=np.bool)\n",
        "\n",
        "for i, sequences in enumerate(sequences):\n",
        "    for t, char in enumerate(sequences):\n",
        "        X_train[i, t, char_indices[char]] = 1\n",
        "        y_train[i, char_indices[next_chars[i]]] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Um-H1ACgPYGk",
        "colab_type": "text"
      },
      "source": [
        "Build an LSTM language model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-FKsVjdPYGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, LSTM\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(512, input_shape=(MAXLEN, len(chars)), dropout=0.5, return_sequences=True))\n",
        "model.add(LSTM(512, dropout=0.5))\n",
        "model.add(Dense(len(chars)))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "optimizer = RMSprop(lr=0.001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "II7dmYm7PYGn",
        "colab_type": "text"
      },
      "source": [
        "Define a helper function for sampling characters from a probability distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J26CDcz0PYGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMqXg-7FPYH5",
        "colab_type": "text"
      },
      "source": [
        "Define the function which generates reviews using an LSTM language model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9woBLqcPYH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate(seed, temperature=1.0):\n",
        "    sentence = MAXLEN * '\\n' + seed\n",
        "    sentence = sentence[-MAXLEN:]\n",
        "    generated = seed\n",
        "\n",
        "    next_char = None\n",
        "    while next_char != '\\n':\n",
        "        X_pred = np.zeros((1, MAXLEN, len(chars)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            X_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "        y_pred = model.predict(X_pred, verbose=0)[0]\n",
        "        next_index = sample(y_pred, temperature)\n",
        "        next_char = indices_char[next_index]\n",
        "\n",
        "        generated += next_char\n",
        "        sentence = sentence[1:] + next_char\n",
        "    return generated[0:-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXG-w4FaPYH-",
        "colab_type": "text"
      },
      "source": [
        "Train the model and print a sample after every iteration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2VjqyrpPYIB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 50\n",
        "\n",
        "old_loss = None\n",
        "for iteration in range(1, EPOCHS + 1):\n",
        "    print()\n",
        "    print('-' * 50)\n",
        "    print('Iteration', iteration)\n",
        "            \n",
        "    history = model.fit(X_train, y_train, batch_size=512, epochs=1)\n",
        "    loss = history.history['loss'][0]\n",
        "    if old_loss != None and old_loss < loss:\n",
        "        print(\"Loss explosion.\")\n",
        "        break\n",
        "    old_loss = loss\n",
        "    start_index = np.random.randint(0, len(data) - MAXLEN - 1)\n",
        "    sentence = data[start_index: start_index + MAXLEN]\n",
        "    print(generate(sentence))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0FBEUWfPYID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.save_weights(\"lstm_lm.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4fAnRnyM4Xw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://www.mlcollege.com/data/lstm_lm.h5\n",
        "model.load_weights(\"lstm_lm.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDtZNwcXN0Gi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generate('The service was')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
